- title: 'Unconstrained Facial Action Unit Detection via Latent Feature Domain'
  #date:  'Jul. 2018'
  imgurl: '/images/projects/2021/shao2021unconstrained.png'
  selected: true
  authors:
    - name: <strong>Zhiwen Shao</strong>
      url:  'https://zhiwenshao.github.io/'
    - name: Jianfei Cai
      url:  'https://research.monash.edu/en/persons/jianfei-cai/'
    - name: Tat-Jen Cham
      url:  'https://personal.ntu.edu.sg/astjcham/index.html'  
    - name: Xuequan Lu
      url:  http://www.xuequanlu.com/
    - name: Lizhuang Ma
      url:  'http://dmcv.sjtu.edu.cn/people'  
  publisher:  'IEEE Transactions on Affective Computing, 2021'
  status:   '(CCF B, SCI Q2)'
  #place:   'in San Diego, USA'
  desc: 'We propose an end-to-end unconstrained facial AU detection framework based on domain adaptation, which transfers accurate AU labels from a constrained source domain to an unconstrained target domain by exploiting labels of AU-related facial landmarks. Specifically, we map a source image with label and a target image without label into a latent feature domain by combining source landmark-related feature with target landmark-free feature. Due to the combination of source AU-related information and target AU-free information, the latent feature domain with transferred source label can be learned by maximizing the target-domain AU detection performance. Moreover, we introduce a novel landmark adversarial loss to disentangle the landmark-free feature from the landmark-related feature by treating the adversarial learning as a multi-player minimax game.'
  tags:
    - name: 'arXiv'
      url:  'https://arxiv.org/abs/1903.10143'
    - name: 'code'
      url:  'https://github.com/ZhiwenShao/ADLD'  
    #- name: 'pdf'
    #  url:  'https://zhiwenshao.github.io/pdfs/projects/2017/zhu2017better.pdf'
    #- name: 'site'
    #  url:  'http://www.sfu.ca/~zhiweid/projects/SIF_project.html'
    
- title: 'Sketch-to-Photo Face Generation Based on Semantic Consistency Preserving and Similar Connected Component Refinement'
  #date:  'Jul. 2020'
  imgurl: '/images/projects/2021/li2021sketch.png'
  selected: true
  authors:
    - name: Luying Li
      url:  false
    - name: Junshu Tang
      url:  false
    - name: <strong>Zhiwen Shao*</strong>
      url:  'https://zhiwenshao.github.io/'
    - name: Xin Tan
      url:  false
    - name: Lizhuang Ma
      url:  'http://dmcv.sjtu.edu.cn/people'  
  publisher:  'The Visual Computer (TVC), 2021'
  status:   '(CCF C, SCI Q4)'
  #place:   'in London, United Kingdom'
  desc: 'We propose a two-stage sketch-to-photo generative adversarial network for face generation. In the first stage, we propose a semantic loss to maintain semantic consistency. In the second stage, we define the similar connected component and propose a color refinement loss to generate fine-grained details. Moreover, we introduce a multi-scale discriminator and design a patch-level local discriminator. We also propose a texture loss to enhance the local fidelity of synthesized images.'
  tags:
    #- name: 'arXiv'
    #  url:  'https://arxiv.org/abs/2004.09769'
    #- name: 'pdf'
    #  url:  'https://zhiwenshao.github.io/pdfs/projects/2017/shao2017learning.pdf'
    #- name: 'code'
    #  url:  'https://github.com/junshutang/EGGAN'
    #- name: 'site'
    #  url:  'http://www.sfu.ca/~zhiweid/projects/SIF_project.html'

- title: 'Explicit Facial Expression Transfer via Fine-Grained Representations'
  #date:  'Jul. 2018'
  imgurl: '/images/projects/2021/shao2021explicit.png'
  selected: true
  authors:
    - name: <strong>Zhiwen Shao</strong>
      url:  'https://zhiwenshao.github.io/'
    - name: Hengliang Zhu
      url:  false
    - name: Junshu Tang
      url:  false
    - name: Xuequan Lu
      url:  http://www.xuequanlu.com/
    - name: Lizhuang Ma
      url:  'http://dmcv.sjtu.edu.cn/people'  
  publisher:  'IEEE Transactions on Image Processing (TIP), 2021'
  status:   '(CCF A, SCI Q1)'
  #place:   'in San Diego, USA'
  desc: 'We propose to explicitly transfer facial expression by directly mapping two unpaired input images to two synthesized images with swapped expressions. Specifically, considering AUs semantically describe fine-grained expression details, we propose a novel multi-class adversarial training method to disentangle input images into two types of fine-grained representations: AU-related feature and AU-free feature. Then, we can synthesize new images with preserved identities and swapped expressions by combining AU-free features with swapped AU-related features. Moreover, to obtain reliable expression transfer results of the unpaired input, we introduce a swap consistency loss to make the synthesized images and self-reconstructed images indistinguishable.'
  tags:
    - name: 'arXiv'
      url:  'https://arxiv.org/abs/1909.02967'
    #- name: 'code'
    #  url:  'https://github.com/ZhiwenShao/PyTorch-JAANet'  
    #- name: 'pdf'
    #  url:  'https://zhiwenshao.github.io/pdfs/projects/2017/zhu2017better.pdf'
    #- name: 'site'
    #  url:  'http://www.sfu.ca/~zhiweid/projects/SIF_project.html'
    
- title: 'EGGAN: Learning Latent Space for Fine-Grained Expression Manipulation'
  #date:  'Jul. 2020'
  imgurl: '/images/projects/2021/tang2021eggan.png'
  selected: true
  authors:
    - name: Junshu Tang
      url:  false
    - name: <strong>Zhiwen Shao*</strong>
      url:  'https://zhiwenshao.github.io/'
    - name: Lizhuang Ma
      url:  'http://dmcv.sjtu.edu.cn/people'  
  publisher:  'IEEE Multimedia (MM), 2021'
  status:   '(SCI Q2)'
  #place:   'in London, United Kingdom'
  desc: 'We propose an end-to-end expression-guided generative adversarial network (EGGAN), which synthesizes an image with expected expression given continuous expression label and structured latent code. In particular, an adversarial autoencoder is used to translate a source image into a structured latent space. The encoded latent code and the target expression label are input to a conditional GAN to synthesize an image with the target expression. Moreover, a perceptual loss and a multi-scale structural similarity loss are introduced to preserve facial identity and global shape during expression manipulation.'
  tags:
    #- name: 'arXiv'
    #  url:  'https://arxiv.org/abs/2004.09769'
    #- name: 'pdf'
    #  url:  'https://zhiwenshao.github.io/pdfs/projects/2017/shao2017learning.pdf'
    - name: 'code'
      url:  'https://github.com/junshutang/EGGAN'
    #- name: 'site'
    #  url:  'http://www.sfu.ca/~zhiweid/projects/SIF_project.html'

- title: 'JÃ‚A-Net: Joint Facial Action Unit Detection and Face Alignment via Adaptive Attention'
  #date:  'Jul. 2018'
  imgurl: '/images/projects/2020/shao2020jaa.png'
  selected: true
  authors:
    - name: <strong>Zhiwen Shao</strong>
      url:  'https://zhiwenshao.github.io/'
    - name: Zhilei Liu
      url:  'http://cic.tju.edu.cn/faculty/zhileiliu/'
    - name: Jianfei Cai
      url:  'https://research.monash.edu/en/persons/jianfei-cai/'
    - name: Lizhuang Ma
      url:  'http://dmcv.sjtu.edu.cn/people'  
  publisher:  'International Journal of Computer Vision (IJCV), 2021'
  status:   '(CCF A, SCI Q1)'
  #place:   'in San Diego, USA'
  desc: 'We propose a novel end-to-end deep learning framework for joint AU detection and face alignment, which has not been explored before. In particular, multi-scale shared feature is learned firstly, and high-level feature of face alignment is fed into AU detection. Moreover, to extract precise local features, we propose an adaptive attention learning module to refine the attention map of each AU adaptively. Finally, the assembled local features are integrated with face alignment feature and global feature for AU detection.'
  tags:
    - name: 'arXiv'
      url:  'https://arxiv.org/abs/2003.08834'
    - name: 'code'
      url:  'https://github.com/ZhiwenShao/PyTorch-JAANet'  
    #- name: 'pdf'
    #  url:  'https://zhiwenshao.github.io/pdfs/projects/2017/zhu2017better.pdf'
    #- name: 'site'
    #  url:  'http://www.sfu.ca/~zhiweid/projects/SIF_project.html'
    
- title: 'CPCS: Critical Points Guided Clustering and Sampling for Point Cloud Analysis'
  date:  'Nov. 2020'
  imgurl: '/images/projects/2020/wang2020cpcs.png'
  selected: true
  authors:
    - name: Wei Wang
      url:  false
    - name: <strong>Zhiwen Shao*</strong>
      url:  'https://zhiwenshao.github.io/'
    - name: Wencai Zhong
      url:  false
    - name: Lizhuang Ma
      url:  'http://dmcv.sjtu.edu.cn/people'  
  publisher:  'ICONIP 2020'
  status:   '(CCF C)'
  place:   'in Bangkok, Thailand'
  desc: 'We introduce the Expectation-Maximization Attention module, to find the critical subset points and cluster the other points around them. Moreover, we explore a point cloud sampling strategy to sample points based on the critical subset.'
  #tags:
    #- name: 'arXiv'
    #  url:  'https://arxiv.org/abs/2004.09769'
    #- name: 'pdf'
    #  url:  'https://zhiwenshao.github.io/pdfs/projects/2017/shao2017learning.pdf'
    #- name: 'code'
    #  url:  'https://github.com/ZhiwenShao/MCNet'
    #- name: 'site'
    #  url:  'http://www.sfu.ca/~zhiweid/projects/SIF_project.html'

- title: '"Forget" the Forget Gate: Estimating Anomalies in Videos using Self-contained Long Short-Term Memory Networks'
  date:  'Oct. 2020'
  imgurl: '/images/projects/2020/fanta2020forget.png'
  selected: true
  authors:
    - name: Habtamu Fanta
      url:  false
    - name: <strong>Zhiwen Shao*</strong>
      url:  'https://zhiwenshao.github.io/'
    - name: Lizhuang Ma
      url:  'http://dmcv.sjtu.edu.cn/people'  
  publisher:  'CGI 2020'
  status:   '(CCF C, oral)'
  place:   'in Geneva, Switzerland'
  desc: 'We introduce a bi-gated, light LSTM cell by discarding the forget gate and introducing sigmoid activation. Specifically, the proposed LSTM architecture fully sustains content from previous hidden state thereby enabling the trained model to be robust and make context-independent decision during evaluation. Removing the forget gate results in a simplified and undemanding LSTM cell with improved performance and computational efficiency.'
  #tags:
    #- name: 'arXiv'
    #  url:  'https://arxiv.org/abs/2004.09769'
    #- name: 'pdf'
    #  url:  'https://zhiwenshao.github.io/pdfs/projects/2017/shao2017learning.pdf'
    #- name: 'code'
    #  url:  'https://github.com/ZhiwenShao/MCNet'
    #- name: 'site'
    #  url:  'http://www.sfu.ca/~zhiweid/projects/SIF_project.html'
    
- title: 'Deep Multi-Center Learning for Face Alignment'
  #date:  'Jul. 2018'
  imgurl: '/images/projects/2018/shao2018deepmulti.png'
  selected: true
  authors:
    - name: <strong>Zhiwen Shao</strong>
      url:  'https://zhiwenshao.github.io/'
    - name: Hengliang Zhu
      url:  false
    - name: Xin Tan
      url:  false
    - name: Yangyang Hao
      url:  false
    - name: Lizhuang Ma
      url:  'http://dmcv.sjtu.edu.cn/people'  
  publisher:  'Neurocomputing, 2020'
  status:   '(CCF C, SCI Q2)'
  #place:   'in San Diego, USA'
  desc: 'We propose a novel deep learning framework named Multi-Center Learning with multiple shape prediction layers for face alignment. In particular, each shape prediction layer emphasizes on the detection of a certain cluster of semantically relevant landmarks respectively. Challenging landmarks are focused firstly, and each cluster of landmarks is further optimized respectively. Moreover, to reduce the model complexity, we propose a model assembling method to integrate multiple shape prediction layers into one shape prediction layer.'
  tags:
    - name: 'arXiv'
      url:  'https://arxiv.org/abs/1808.01558'
    - name: 'code'
      url:  'https://github.com/ZhiwenShao/MCNet-Extension'  
    #- name: 'pdf'
    #  url:  'https://zhiwenshao.github.io/pdfs/projects/2017/zhu2017better.pdf'
    #- name: 'site'
    #  url:  'http://www.sfu.ca/~zhiweid/projects/SIF_project.html'
    
- title: 'SiTGRU: Single-Tunnelled Gated Recurrent Unit for Abnormality Detection'
  #date:  'Jul. 2018'
  imgurl: '/images/projects/2020/fanta2020sitgru.png'
  selected: true
  authors:
    - name: Habtamu Fanta
      url:  false
    - name: <strong>Zhiwen Shao*</strong>
      url:  'https://zhiwenshao.github.io/'
    - name: Lizhuang Ma
      url:  'http://dmcv.sjtu.edu.cn/people'
  publisher:  'Information Sciences (INS), 2020'
  status:   '(CCF B, SCI Q2)'
  #place:   'in San Diego, USA'
  desc: 'We propose a novel version of Gated Recurrent Unit (GRU), called Single-Tunnelled GRU for abnormality detection. Particularly, the Single-Tunnelled GRU discards the heavy-weighted reset gate from GRU cells that overlooks the importance of past content by only favouring current input to obtain an optimized single-gated-cell model. Moreover, we substitute the hyperbolic tangent activation in standard GRUs with sigmoid activation, as the former suffers from performance loss in deeper networks.'
  tags:
    - name: 'arXiv'
      url:  'https://arxiv.org/abs/2003.13528'
    #- name: 'code'
    #  url:  'https://github.com/ZhiwenShao/ARL'  
    #- name: 'pdf'
    #  url:  'https://zhiwenshao.github.io/pdfs/projects/2017/zhu2017better.pdf'
    #- name: 'site'
    #  url:  'http://www.sfu.ca/~zhiweid/projects/SIF_project.html'

- title: 'Fine-Grained Expression Manipulation via Structured Latent Space'
  date:  'Jul. 2020'
  imgurl: '/images/projects/2020/tang2020finegrained.png'
  selected: true
  authors:
    - name: Junshu Tang
      url:  false
    - name: <strong>Zhiwen Shao*</strong>
      url:  'https://zhiwenshao.github.io/'
    - name: Lizhuang Ma
      url:  'http://dmcv.sjtu.edu.cn/people'  
  publisher:  'ICME 2020'
  status:   '(CCF B, oral)'
  place:   'in London, United Kingdom'
  desc: 'We propose an end-to-end expression-guided generative adversarial network (EGGAN), which utilizes structured latent codes and continuous expression labels as input to generate images with expected expressions. Specifically, we adopt an adversarial autoencoder to map a source image into a structured latent space. Then, given the source latent code and the target expression label, we employ a conditional GAN to generate a new image with the target expression. Moreover, we introduce a perceptual loss and a multi-scale structural similarity loss to preserve identity and global shape during generation.'
  tags:
    - name: 'arXiv'
      url:  'https://arxiv.org/abs/2004.09769'
    #- name: 'pdf'
    #  url:  'https://zhiwenshao.github.io/pdfs/projects/2017/shao2017learning.pdf'
    - name: 'code'
      url:  'https://github.com/junshutang/EGGAN'
    #- name: 'site'
    #  url:  'http://www.sfu.ca/~zhiweid/projects/SIF_project.html'
        
- title: 'Facial Action Unit Detection Using Attention and Relation Learning'
  #date:  'Jul. 2018'
  imgurl: '/images/projects/2019/shao2019facial.png'
  selected: true
  authors:
    - name: <strong>Zhiwen Shao</strong>
      url:  'https://zhiwenshao.github.io/'
    - name: Zhilei Liu
      url:  'http://cic.tju.edu.cn/faculty/zhileiliu/'
    - name: Jianfei Cai
      url:  'https://research.monash.edu/en/persons/jianfei-cai/'
    - name: Yunsheng Wu
      url:  false
    - name: Lizhuang Ma
      url:  'http://dmcv.sjtu.edu.cn/people'
  publisher:  'IEEE Transactions on Affective Computing, 2019'
  status:   '(CCF B, SCI Q2)'
  #place:   'in San Diego, USA'
  desc: 'We propose an end-to-end deep learning based attention and relation learning framework for AU detection with only AU labels, which has not been explored before. In particular, multi-scale features shared by each AU are learned firstly, and then both channel-wise and spatial attentions are adaptively learned to select and extract AU-related local features. Moreover, pixel-level relations for AUs are further captured to refine spatial attentions so as to extract more relevant local features. Without changing the network architecture, our framework can be easily extended for AU intensity estimation.'
  tags:
    - name: 'arXiv'
      url:  'https://arxiv.org/abs/1808.03457'
    - name: 'code'
      url:  'https://github.com/ZhiwenShao/ARL'  
    #- name: 'pdf'
    #  url:  'https://zhiwenshao.github.io/pdfs/projects/2017/zhu2017better.pdf'
    #- name: 'site'
    #  url:  'http://www.sfu.ca/~zhiweid/projects/SIF_project.html'
    
- title: 'Deep Adaptive Attention for Joint Facial Action Unit Detection and Face Alignment'
  date:  'Sept. 2018'
  imgurl: '/images/projects/2018/shao2018deep.png'
  selected: true
  authors:
    - name: <strong>Zhiwen Shao</strong>
      url:  'https://zhiwenshao.github.io/'
    - name: Zhilei Liu
      url:  'http://cic.tju.edu.cn/faculty/zhileiliu/'
    - name: Jianfei Cai
      url:  'https://research.monash.edu/en/persons/jianfei-cai/'
    - name: Lizhuang Ma
      url:  'http://dmcv.sjtu.edu.cn/people'  
  publisher:  'ECCV 2018'
  status:   '(CCF B, Tsinghua A)'
  place:   'in Munich, Germany'
  desc: 'We propose a novel end-to-end deep learning framework for joint AU detection and face alignment, which has not been explored before. In particular, multi-scale shared features are learned firstly, and high-level features of face alignment are fed into AU detection. Moreover, to extract precise local features, we propose an adaptive attention learning module to refine the attention map of each AU adaptively. Finally, the assembled local features are integrated with face alignment features and global features for AU detection.'
  tags:
    - name: 'arXiv'
      url:  'https://arxiv.org/abs/1803.05588'
    - name: 'pdf'
      url:  'http://openaccess.thecvf.com/content_ECCV_2018/papers/Zhiwen_Shao_Deep_Adaptive_Attention_ECCV_2018_paper.pdf'
    - name: 'code'
      url:  'https://github.com/ZhiwenShao/JAANet'
    #- name: 'site'
    #  url:  'http://www.sfu.ca/~zhiweid/projects/SIF_project.html'
    
- title: 'Learning a Multi-Center Convolutional Network for Unconstrained Face Alignment'
  date:  'Jul. 2017'
  imgurl: '/images/projects/2017/shao2017learning.png'
  selected: true
  authors:
    - name: <strong>Zhiwen Shao</strong>
      url:  'https://zhiwenshao.github.io/'
    - name: Hengliang Zhu
      url:  false
    - name: Yangyang Hao
      url:  false
    - name: Min  Wang
      url:  false
    - name: Lizhuang Ma
      url:  'http://dmcv.sjtu.edu.cn/people'  
  publisher:  'ICME 2017'
  status:   '(CCF B, oral)'
  place:   'in Hong Kong'
  desc: 'We propose a novel multi-center convolutional neural network for unconstrained face alignment. To utilize structural correlations among different facial landmarks, we determine several clusters based on their spatial position. We pre-train our network to learn generic feature representations. We further fine-tune the pre-trained model to emphasize on locating a certain cluster of landmarks respectively. Fine-tuning contributes to searching an optimal solution smoothly without deviating from the pre-trained model excessively. We obtain an excellent solution by combining multiple fine-tuned models.'
  tags:
    #- name: 'arXiv'
    #  url:  'https://arxiv.org/abs/1608.00207'
    - name: 'pdf'
      url:  'https://zhiwenshao.github.io/pdfs/projects/2017/shao2017learning.pdf'
    - name: 'code'
      url:  'https://github.com/ZhiwenShao/MCNet'
    #- name: 'site'
    #  url:  'http://www.sfu.ca/~zhiweid/projects/SIF_project.html'

- title: 'Learning Deep Representation from Coarse to Fine for Face Alignment'
  date:  'Jul. 2016'
  imgurl: '/images/projects/2016/shao2016learning.png'
  selected: true
  authors:
    - name: <strong>Zhiwen Shao</strong>
      url:  'https://zhiwenshao.github.io/'
    - name: Shouhong Ding
      url:  false
    - name: Yiru Zhao
      url:  false
    - name: Qinchuan  Zhang
      url:  false
    - name: Lizhuang Ma
      url:  'http://dmcv.sjtu.edu.cn/people'  
  publisher:  'ICME 2016'
  status:   '(CCF B)'
  place:   'in Seattle, USA'
  desc: 'We propose a novel face alignment method that trains deep convolutional network from coarse to fine. It divides given landmarks into principal subset and elaborate subset. We firstly keep a large weight for principal subset to make our network primarily predict their locations while slightly take elaborate subset into account. Next the weight of principal subset is gradually decreased until two subsets have equivalent weights. This process contributes to learn a good initial model and search the optimal model smoothly to avoid missing fairly good intermediate models in subsequent procedures.'
  tags:
    - name: 'arXiv'
      url:  'https://arxiv.org/abs/1608.00207'
    - name: 'pdf'
      url:  'https://zhiwenshao.github.io/pdfs/projects/2016/shao2016learning.pdf'
    - name: 'code'
      url:  'https://github.com/ZhiwenShao/CFT'
    #- name: 'site'
    #  url:  'http://www.sfu.ca/~zhiweid/projects/SIF_project.html'

- title: 'Face Alignment by Deep Convolutional Network with Adaptive Learning Rate'
  date:  'Mar. 2016'
  imgurl: '/images/projects/2016/shao2016face.png'
  selected: true
  authors:
    - name: <strong>Zhiwen Shao</strong>
      url:  'https://zhiwenshao.github.io/'
    - name: Shouhong Ding
      url:  false
    - name: Hengliang Zhu
      url:  false
    - name: Chengjie Wang
      url:  false
    - name: Lizhuang Ma
      url:  'http://dmcv.sjtu.edu.cn/people'  
  publisher:  'ICASSP 2016'
  status:   '(CCF B, oral)'
  place:   'in Shanghai, China'
  desc: 'We propose a novel data augmentation strategy. And we design an innovative training algorithm with adaptive learning rate for two iterative procedures, which helps the network to search an optimal solution. Our convolutional network can learn global high-level features and directly predict the coordinates of facial landmarks.'
  tags:
    - name: 'pdf'
      url:  'https://zhiwenshao.github.io/pdfs/projects/2016/shao2016face.pdf'
    - name: 'tool'
      url:  'https://github.com/ZhiwenShao/ARL-tool'
    #- name: 'site'
    #  url:  'http://www.sfu.ca/~zhiweid/projects/SIF_project.html'

- title: 'FVNet: 3D Front-View Proposal Generation for Real-Time Object Detection from Point Clouds'
  date:  'Oct. 2019'
  imgurl: '/images/projects/2019/zhou2019fvnet.png'
  selected: true
  authors:
    - name: Jie Zhou
      url:  false
    - name: Xin Tan
      url:  false
    - name: <strong>Zhiwen Shao*</strong>
      url:  'https://zhiwenshao.github.io/'  
    - name: Lizhuang Ma
      url:  'http://dmcv.sjtu.edu.cn/people'  
  publisher:  'CISP-BMEI 2019'
  #status:   '(CCF B)'
  place:   'in Huaqiao, China'
  desc: 'We propose a novel framework called FVNet for 3D front-view proposal generation and object detection from point clouds. It consists of two stages: generation of front-view proposals and estimation of 3D bounding box parameters. We first project point clouds onto a cylindrical surface to generate front-view feature maps which retains rich information. We then introduce a proposal generation network to predict 3D region proposals from the generated maps and further extrude objects of interest from the whole point cloud. Finally, we present another network to extract the point-wise features from the extruded object points and regress the final 3D bounding box parameters in the canonical coordinates.'
  tags:
    - name: 'arXiv'
      url:  'https://arxiv.org/abs/1903.10750'
    #- name: 'pdf'
    #  url:  'https://zhiwenshao.github.io/pdfs/projects/2017/tang2017deep.pdf'
    #- name: 'site'
    #  url:  'http://www.sfu.ca/~zhiweid/projects/SIF_project.html'    

- title: 'Feedback Cascade Regression Model for Face Alignment'
  #date:  'Jul. 2018'
  imgurl: '/images/projects/2019/hao2019feedback.png'
  selected: false
  authors:
    - name: Yangyang Hao
      url:  false
    - name: Hengliang Zhu
      url:  false
    - name: <strong>Zhiwen Shao</strong>
      url:  'https://zhiwenshao.github.io/'
    - name: Lizhuang Ma
      url:  'http://dmcv.sjtu.edu.cn/people'  
  publisher:  'IET Computer Vision, 2019'
  status:   '(CCF C, SCI Q4)'
  #place:   'in San Diego, USA'
  desc: 'We propose a new pipeline of salient-to-inner-to-all to progressively compute the locations of landmarks. Additionally, a feedback process is utilised to improve the robustness of regression. They bring out a pose-invariant shape retrieval method to generate the discriminative initialisation.'
  tags:
    #- name: 'arXiv'
    #  url:  'https://arxiv.org/abs/1808.01558'
    #- name: 'code'
    #  url:  'https://github.com/ZhiwenShao/MCNet-Extension'  
    - name: 'pdf'
      url:  'https://zhiwenshao.github.io/pdfs/projects/2019/hao2019feedback.pdf'
    #- name: 'site'
    #  url:  'http://www.sfu.ca/~zhiweid/projects/SIF_project.html'
    
- title: 'Better Initialization for Regression-Based Face Alignment'
  #date:  'Jul. 2018'
  imgurl: '/images/projects/2017/zhu2017better.png'
  selected: false
  authors:
    - name: Hengliang Zhu
      url:  false
    - name: Bin Sheng
      url:  'http://english.seiee.sjtu.edu.cn/english/detail/841_963.htm'
    - name: <strong>Zhiwen Shao</strong>
      url:  'https://zhiwenshao.github.io/'
    - name: Yangyang Hao
      url:  false
    - name: Xiaonan Hou
      url:  false
    - name: Lizhuang Ma
      url:  'http://dmcv.sjtu.edu.cn/people'  
  publisher:  'Computers & Graphics, 2018'
  status:   '(CCF C, SCI Q4)'
  #place:   'in San Diego, USA'
  desc: 'We discuss how to improve initialization by studying a neighborhood representation prior, leveraging neighboring faces to obtain a high-quality initial shape. In order to further improve the estimation precision of each facial landmark, we propose a face-like landmark adjustment algorithm to refine the face shape.'
  tags:
    #- name: 'arXiv'
    #  url:  'https://arxiv.org/abs/1608.00207'
    - name: 'pdf'
      url:  'https://zhiwenshao.github.io/pdfs/projects/2017/zhu2017better.pdf'
    #- name: 'site'
    #  url:  'http://www.sfu.ca/~zhiweid/projects/SIF_project.html'
    
- title: 'Saliency Detection by Deep Network with Boundary Refinement and Global Context'
  date:  'Jul. 2018'
  imgurl: '/images/projects/2018/tan2018saliency.png'
  selected: false
  authors:
    - name: Xin Tan
      url:  false
    - name: Hengliang Zhu
      url:  false
    - name: <strong>Zhiwen Shao</strong>
      url:  'https://zhiwenshao.github.io/'  
    - name: Xiaonan Hou
      url:  false
    - name: Yangyang Hao
      url:  false
    - name: Lizhuang Ma
      url:  'http://dmcv.sjtu.edu.cn/people'  
  publisher:  'ICME 2018'
  status:   '(CCF B)'
  place:   'in San Diego, USA'
  desc: 'We propose to embed the boundary enhancement block (BEB) into the network to refine edge. It keeps the details by the mutual-coupling convolutional layers. Besides, we employ a pooling pyramid that utilizes the multi-level feature informations to search global context, and it also contributes as an auxiliary supervision. The final saliency map is obtained by fusing the edge refinement with global context extraction.'
  tags:
    #- name: 'arXiv'
    #  url:  'https://arxiv.org/abs/1608.00207'
    - name: 'pdf'
      url:  'https://zhiwenshao.github.io/pdfs/projects/2018/tan2018saliency.pdf'
    - name: 'code'
      url:  'https://github.com/tanxin2017/Saliency-GBR'
      
- title: 'Multi-Path Feature Fusion Network for Saliency Detection'
  date:  'Jul. 2018'
  imgurl: '/images/projects/2018/zhu2018multi.png'
  selected: false
  authors:
    - name: Hengliang Zhu
      url:  false
    - name: Xin Tan
      url:  false
    - name: <strong>Zhiwen Shao</strong>
      url:  'https://zhiwenshao.github.io/'
    - name: Yangyang Hao
      url:  false
    - name: Lizhuang Ma
      url:  'http://dmcv.sjtu.edu.cn/people'  
  publisher:  'ICME 2018'
  status:   '(CCF B)'
  place:   'in San Diego, USA'
  desc: 'We exploit a multi-path feature fusion model for saliency detection. The proposed model is a fully convolutional network with raw images as input and saliency maps as output. In particular, we propose a multi-path fusion strategy for deriving the intrinsic features of salient objects. The structure has the ability of capturing the low-level visual features and generating the boundary-preserving saliency maps. Moreover, a coupled structure module is proposed in our model, which helps to explore the high-level semantic properties of salient objects.'
  tags:
    #- name: 'arXiv'
    #  url:  'https://arxiv.org/abs/1608.00207'
    - name: 'pdf'
      url:  'https://zhiwenshao.github.io/pdfs/projects/2018/zhu2018multi.pdf'
    #- name: 'site'
    #  url:  'http://www.sfu.ca/~zhiweid/projects/SIF_project.html'
    
- title: 'Facial Landmark Detection Under Large Pose'
  date:  'Dec. 2018'
  imgurl: '/images/projects/2018/hao2018facial.png'
  selected: false
  authors:
    - name: Yangyang Hao
      url:  false
    - name: Hengliang Zhu
      url:  false
    - name: <strong>Zhiwen Shao</strong>
      url:  'https://zhiwenshao.github.io/'  
    - name: Xin Tan
      url:  false
    - name: Lizhuang Ma
      url:  'http://dmcv.sjtu.edu.cn/people'  
  publisher:  'ICONIP 2018'
  status:   '(CCF C, oral)'
  place:   'in Siem Reap, Cambodia'
  desc: 'We propose a two-stage cascade regression framework using patch-difference features to overcome the above problem. In the first stage, by applying the patch-difference feature and augmenting the large pose samples to the classical shape regression model, salient landmarks (eye centers, nose, mouth corners) can be located precisely. In the second stage, by applying enhanced feature section constraint to the patch-difference feature, multi-landmark detection is achieved.'
  tags:
    #- name: 'arXiv'
    #  url:  'https://arxiv.org/abs/1608.00207'
    - name: 'pdf'
      url:  'https://zhiwenshao.github.io/pdfs/projects/2018/hao2018facial.pdf'
    #- name: 'site'
    #  url:  'http://www.sfu.ca/~zhiweid/projects/SIF_project.html'    
    
- title: 'Deep Feature Selection and Projection for Cross-Age Face Retrieval'
  date:  'Oct. 2017'
  imgurl: '/images/projects/2017/tang2017deep.png'
  selected: false
  authors:
    - name: Kaihua Tang
      url:  'https://kaihuatang.github.io/'
    - name: Xiaonan Hou
      url:  false
    - name: <strong>Zhiwen Shao</strong>
      url:  'https://zhiwenshao.github.io/'  
    - name: Lizhuang Ma
      url:  'http://dmcv.sjtu.edu.cn/people'  
  publisher:  'CISP-BMEI 2017'
  #status:   '(CCF B)'
  place:   'in Shanghai, China'
  desc: 'We propose a deep feature based framework for face retrieval problem. Our framework uses deep CNNs feature descriptor and two well designed post-processing methods to achieve age-invariance. To the best of our knowledge, this is the first deep feature based method in cross-age face retrieval problem.'
  tags:
    #- name: 'arXiv'
    #  url:  'https://arxiv.org/abs/1608.00207'
    - name: 'pdf'
      url:  'https://zhiwenshao.github.io/pdfs/projects/2017/tang2017deep.pdf'
    #- name: 'site'
    #  url:  'http://www.sfu.ca/~zhiweid/projects/SIF_project.html'    

- title: 'LSOD: Local Sparse Orthogonal Descriptor for Image Matching'
  date:  'Oct. 2016'
  imgurl: '/images/projects/2016/zhao2016lsod.png'
  selected: false
  authors:
    - name: Yiru Zhao
      url:  false
    - name: Yaoyi Li
      url:  'http://bcmi.sjtu.edu.cn/~liyaoyi/'
    - name: <strong>Zhiwen Shao</strong>
      url:  'https://zhiwenshao.github.io/'  
    - name: Hongtao Lu
      url:  'http://www.cs.sjtu.edu.cn/en/PeopleDetail.aspx?id=156'  
  publisher:  'MM 2016'
  status:   '(CCF A, short)'
  place:   'in Amsterdam, Netherlands'
  desc: 'We propose a novel method for feature description used for image matching in this paper. Our method is inspired by the autoencoder, an artificial neural network designed for learning efficient codings. Sparse and orthogonal constraints are imposed on the autoencoder and make it a highly discriminative descriptor. It is shown that the proposed descriptor is not only invariant to geometric and photometric transformations (such as viewpoint change, intensity change, noise, image blur and JPEG compression), but also highly efficient.'
  tags:
    #- name: 'arXiv'
    #  url:  'https://arxiv.org/abs/1608.00207'
    - name: 'pdf'
      url:  'https://zhiwenshao.github.io/pdfs/projects/2016/zhao2016lsod.pdf'
    #- name: 'site'
    #  url:  'http://www.sfu.ca/~zhiweid/projects/SIF_project.html'
